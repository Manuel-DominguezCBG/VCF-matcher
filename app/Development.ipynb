{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook to develop the script, generate and analyse some results.\n",
    "\n",
    "I have started the development of the program in this notebook. Then, I have adapted the code to have a script\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "Created on \n",
    "\n",
    "@author: manuel.dominguezbecerra@nhs.net\n",
    "\n",
    "'''\n",
    "\n",
    "# Import libraries \n",
    "import argparse                          # pip install argparse\n",
    "import pandas as pd                      \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# To allow the user to load the file after running \"python run.ppy\"\n",
    "\n",
    "# Example:    python run.py -- /path/file_name1 -- /path/file_name2\n",
    "\n",
    "   ### 1. Load the files\n",
    "    \n",
    "# During the development of this application, I have needed to run the script many times\n",
    "# To do this in an easy way, I directly introduce here the path/file_name in a variable\n",
    "# As it can be seen below\n",
    "\n",
    "Name_file1 = \"/Users/monkiky/Desktop/VCF-matcher/Twin_brothers/W1717693_S1.vcf\"\n",
    "\n",
    "Name_file2 = \"/Users/monkiky/Desktop/VCF-matcher/Twin_brothers/W1816869_S14.vcf\"\n",
    "\n",
    "# In the script, the previous two lines doesn´t appear and the following lines are incommeneted\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--vcf1', type=str, required=True)\n",
    "#parser.add_argument('--vcf2', type=int, required=True)\n",
    "#args = parser.parse_args()\n",
    "#Name_file1 = args.vcf1 \n",
    "#Name_file2 = args.vcf2\n",
    "\n",
    "# This 6 lines allow the user to select the two neccesary files to run the script\n",
    "\n",
    "#During the development, the few lines make running the script easier.\n",
    "# In the run.py script, the previous lines are uncommented and the following lines are deleted.\n",
    "\n",
    "\n",
    "# From here to the end, the following lines are identical that the one find in the script\n",
    "\n",
    "\n",
    "   ### 2. Take the body of the files and ignore meta-data lines\n",
    "\n",
    "# Originally what I did was to delete the metedata and save the data in a new file\n",
    "# This approach was over complicated and doesn´t work in window machines.\n",
    "# Instead of this, the current approach  take directly the data and save it in pandas dataframe object.\n",
    "# This is also a more efficient method.\n",
    "\n",
    "# For the file number 1\n",
    "with open(Name_file1, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "\n",
    "dataA = pd.read_csv(Name_file1, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "# Same for the second file\n",
    "with open(Name_file2, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "            \n",
    "dataB = pd.read_csv(Name_file2, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "\n",
    "# If the data frame has more than 10 columns\n",
    "# that means there are more than 1 sample in the vcf file\n",
    "# If more than one file is found, next lines ask to the user what sample to take.\n",
    "\n",
    "if len(dataA.columns) > 10:\n",
    "     Name_sample1 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file1)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file1), 'contains one sample only.')\n",
    "    Name_sample1 = dataA.columns.tolist()[9]\n",
    "\n",
    "if len(dataB.columns) > 10:\n",
    "     Name_sample2 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file2)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file2), 'contains one sample only.')\n",
    "    Name_sample2 = dataB.columns.tolist()[9]\n",
    "\n",
    "    \n",
    "\n",
    "# The data of the sample is save in the file in one column separated by \":\". \n",
    "# Example: Example:   0/1:100:3501,254:0.0676:20:-100.0000:100\n",
    "\n",
    "# To take the data I want, I need to split and put the fiels in columns\n",
    "\n",
    "\n",
    "tmp_df2 = dataA[Name_sample1].str.split(':', expand=True)\n",
    "\n",
    "#tmp_df2 = tmp_df2.fillna(value=np.nan)\n",
    "#tmp_df2 = tmp_df2.dropna(axis=1, how='any')\n",
    "\n",
    "tmp_df2.columns = dataA.FORMAT.iloc[0].split(':')\n",
    "dataA = pd.concat([dataA, tmp_df2], axis=1)\n",
    "\n",
    "# Results so far\n",
    "#  CHROM       POS ID REF ALT  QUAL FILTER   GT  GQ       AD      VF  NL\n",
    "#  chr1  36931745  .   G   A  34.0     SB  0/1  34  1755,34  0.0190  20\n",
    "\n",
    "# Same for dataB\n",
    "tmp_df3 = dataB[Name_sample2].str.split(':', expand=True)\n",
    "tmp_df3 = tmp_df3.fillna(value=np.nan) \n",
    "tmp_df3 = tmp_df3.dropna(axis=1, how='any') \n",
    "\n",
    "tmp_df3.columns = dataB.FORMAT.iloc[0].split(':')\n",
    "dataB = pd.concat([dataB, tmp_df3], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    ### 3. Filter the variants  \n",
    "    \n",
    "# Two filters are applied here. First, I take only the variants that \"PASS\" the \"FILTER\" field. \n",
    "# This is a mandatory field.\n",
    "\n",
    "# Then, I take only the variants which Variant Frecuency (VF) is highter than. 0.4\n",
    "# This is not a mandatory field in vcf filed\n",
    "\n",
    "# VF is in the 9th column with another data. \n",
    "#we need to extract and put VF data in an independent column first\n",
    "\n",
    "\n",
    "# Now, let´s filter the variant\n",
    "# We dont want variants that doesnt pass the Filter status\n",
    "# This field is mandatory, no condition is needed because it is applied to any type of VCF file.\n",
    "dataA = dataA.query('FILTER == \"PASS\"')\n",
    "dataB = dataB.query('FILTER == \"PASS\"')\n",
    "                    \n",
    "# Now, I apply Variant Frecuency (VF) filter (non-mandatory field)\n",
    "\n",
    "# If there is a VF Genotype fields in the file\n",
    "# Take the variants that are > 0.4\n",
    "# If not, no VF filter is applied\n",
    "\n",
    "if \"VF\" in dataA.columns:\n",
    "    dataA[\"VF\"] = dataA[\"VF\"].astype(float)\n",
    "    dataA = dataA.query('VF > 0.4')\n",
    "    \n",
    "if \"VF\" in dataB.columns:\n",
    "    dataB[\"VF\"] = dataB[\"VF\"].astype(float)\n",
    "    dataB = dataB.query('VF > 0.4')\n",
    "    \n",
    "\n",
    "   ### 4. Variants comparison\n",
    "\n",
    "# Two variants are the same if  CHROM, POS, REF, ALT and GT are equal\n",
    "\n",
    "dataA['CHROMPOSREFALT']= dataA[\"CHROM\"].apply(str)+\".\"+dataA[\"POS\"].apply(str)+dataA[\"REF\"]+\".\"+dataA[\"ALT\"]\n",
    "\n",
    "dataB['CHROMPOSREFALT']= dataB[\"CHROM\"].apply(str)+\".\"+dataB[\"POS\"].apply(str)+dataB[\"REF\"]+\".\"+dataB[\"ALT\"]\n",
    "\n",
    "\n",
    "frames = [dataA[['CHROMPOSREFALT', 'GT']],dataB[['CHROMPOSREFALT', 'GT']]]\n",
    "semi_final_df = pd.concat(frames)\n",
    "# semi_final_df saves the CHROM, POS, REF, ALT in the first column and the GT in the second column\n",
    "\n",
    "\n",
    "#Example:\n",
    "'''\n",
    "CHROMPOSREFALT     GT\n",
    "\n",
    "chr1.123456T.C     0/1       From sample 1\n",
    "chr2.123456A.C     1/1       From sample 1\n",
    "chr1.123456T.C     0/1       From sample 2\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Let´s reduce the number of rows\n",
    "final_df=(semi_final_df.assign(key=semi_final_df.groupby('CHROMPOSREFALT').cumcount())\n",
    "      .pivot('CHROMPOSREFALT','key','GT')\n",
    "      .rename(columns=lambda x:f\"Sample{x+1}\")\n",
    "      .rename_axis(columns=None).reset_index())\n",
    "\n",
    "# Final_df contains all common and non-common variants that passed the filters\n",
    "\n",
    "# The pivot command gives NaNs in the column of the second sample when a variant is only found in one of the samples\n",
    "# This NaN values return errors in the following lines. This is an error I have found when the script was developed\n",
    "# To solve the issue without introducing many changes, NaN values are replace for 99/99 values.\n",
    "final_df = final_df.replace(np.NaN,\"99/99\" )\n",
    "\n",
    "   ### 4. See how many GT match\n",
    "\n",
    "# Variables needed for both type of reports\n",
    "\n",
    "r0 = os.path.basename(Name_file1) # Get the  file name of a path/file_name \n",
    "r1 = Name_sample1                 # Get the name of the sample 1\n",
    "r2 = os.path.basename(Name_file2)\n",
    "r3 = Name_sample2\n",
    "\n",
    "if \"Sample2\" not in final_df.columns:\n",
    "    # If Sample2 is not in final_df, that means there is not common position between the samples.\n",
    "    report0 = '''\n",
    " _____________________________  REPORT  ________________________________________ \n",
    "\n",
    "vcf 1: {0}  AND its sample name: {1}  \n",
    "vcf 2:  {2}  AND its sample name: {3}\n",
    "\n",
    "   No common positions found between samples\n",
    "\n",
    " ____________________________ END REPORT  _______________________________________\n",
    "'''\n",
    "    print(report0.format(r0,r1,r2,r3,))\n",
    "\n",
    "else:    \n",
    "    # else match common position and carry on the report.\n",
    "    final_df[\"Matches\"] = np.where(final_df[\"Sample1\"] == final_df[\"Sample2\"], True, False)\n",
    "    final_df.columns = ['CHROMPOSREFALT',os.path.basename(Name_file1),os.path.basename(Name_file2),\"Matches\" ]\n",
    "\n",
    "    # 6.  To get hom and het \n",
    "\n",
    "    final_df['Genotype1'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[0])\n",
    "    final_df['Genotype2'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[1])\n",
    "    \n",
    "    final_df['Hom/het'] = np.select([final_df['Matches'] & final_df['Genotype1'].eq(final_df['Genotype2']),\n",
    "                       final_df['Matches'] & final_df['Genotype1'].ne(final_df['Genotype2'])],\n",
    "                       choicelist=[\"Hom\", \"Het\"],\n",
    "                       default=pd.NA)\n",
    "\n",
    "   ### 6. Generate results in the terminal\n",
    "\n",
    "# Variable to introduce in the report :\n",
    "    \n",
    "    r4 = final_df['Matches'].value_counts().get(True, 0) # Count trues if any, retunr 0\n",
    "    r5 = final_df['Hom/het'].value_counts().get(\"Hom\", 0)\n",
    "    r6 =final_df['Hom/het'].value_counts().get(\"Het\", 0)\n",
    "    r7 = final_df['Matches'].value_counts().get(False, 0)\n",
    "    r8 = len(final_df)\n",
    "    r9 = r4/(r4+r7)\n",
    "    report = '''\n",
    " _____________________________  REPORT  ________________________________________ \n",
    "\n",
    "vcf 1: {0}  AND its sample name: {1}  \n",
    "vcf 2:  {2}  AND its sample name: {3}\n",
    "\n",
    "                                                  Homozigous: {5} \n",
    "Number of positions with the same genotype: {4} \n",
    "                                                  Heterozigous: {6} \n",
    "                                                \n",
    "                                                  \n",
    "Number of positions with different genotype: {7} \n",
    "                                                  \n",
    "\n",
    "\n",
    "Total positions compared: {8}\n",
    "Percentage in common: {4}/{8}= {9}\n",
    "\n",
    " ____________________________ END REPORT  _______________________________________\n",
    "'''\n",
    "    print(report.format(r0,r1,r2,r3,r4,r5,r6,r7,r8,r9))\n",
    "    \n",
    "    # ========== Results ================== #\n",
    "\n",
    "# To store results in lists and then in df\n",
    "\n",
    "\n",
    " ### This is to create the scatter plot with the matched and unmatched samples\n",
    "\n",
    "# To create the list the first iteration\n",
    "#sampleA = [\"hola\"]\n",
    "#sampleB = [\"hola\"]\n",
    "#Total_positions_comp = [\"hola\"]\n",
    "#Pos_same_genotype = [\"hola\"]\n",
    "#Pos_different_genotyope = [\"hola\"]\n",
    "#Hom = [\"hola\"]\n",
    "#Het = [\"hola\"]\n",
    "\n",
    "#sampleA.append(r1)\n",
    "#sampleB.append(r3)\n",
    "#Total_positions_comp.append(r8)\n",
    "#Pos_same_genotype.append(r4)\n",
    "#Pos_different_genotyope.append(r7)\n",
    "#Hom.append(r5)\n",
    "#Het.append(r6)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample (Name_file):\n",
    "    with open(Name_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "                columns = line[1:-1].split('\\t')\n",
    "                break\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse                          # pip install argparse\n",
    "import pandas as pd                      \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_FILE_1 = \"/Users/monkiky/Desktop/VCF-matcher/Twin_brothers/W1717693_S1.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHROM',\n",
       " 'POS',\n",
       " 'ID',\n",
       " 'REF',\n",
       " 'ALT',\n",
       " 'QUAL',\n",
       " 'FILTER',\n",
       " 'INFO',\n",
       " 'FORMAT',\n",
       " 'W1717693']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_sample (NAME_FILE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>INFO</th>\n",
       "      <th>FORMAT</th>\n",
       "      <th>W1717693</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36931706</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>32.0</td>\n",
       "      <td>SB</td>\n",
       "      <td>DP=1055;TI=NM_172313,NM_156039,NM_000760;GI=CS...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:32:1031,23:0.0218:20:0.0000:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36932103</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>62.0</td>\n",
       "      <td>SB</td>\n",
       "      <td>DP=2094;TI=NM_172313,NM_156039,NM_000760;GI=CS...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:62:2031,47:0.0224:20:0.0000:62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36932108</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>43.0</td>\n",
       "      <td>SB</td>\n",
       "      <td>DP=2136;TI=NM_172313,NM_156039,NM_000760;GI=CS...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:43:2083,42:0.0197:20:0.0000:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36932121</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>65.0</td>\n",
       "      <td>SB</td>\n",
       "      <td>DP=321;TI=NM_172313,NM_156039,NM_000760;GI=CSF...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:65:305,16:0.0498:20:-0.2685:65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36932122</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>100.0</td>\n",
       "      <td>SB</td>\n",
       "      <td>DP=333;TI=NM_172313,NM_156039,NM_000760;GI=CSF...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:100:304,26:0.0781:20:-0.2588:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>chrX</td>\n",
       "      <td>133527688</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>GT</td>\n",
       "      <td>100.0</td>\n",
       "      <td>R8</td>\n",
       "      <td>DP=1090;TI=NM_032335,NM_001015877,NM_032458;GI...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:100:1000,90:0.0826:20:-100.0000:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>chrX</td>\n",
       "      <td>133527928</td>\n",
       "      <td>.</td>\n",
       "      <td>AT</td>\n",
       "      <td>A</td>\n",
       "      <td>50.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>DP=1395;TI=NM_032335,NM_001015877,NM_032458;GI...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:50:1362,33:0.0237:20:-22.4949:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>chrX</td>\n",
       "      <td>133547693</td>\n",
       "      <td>.</td>\n",
       "      <td>TA</td>\n",
       "      <td>T</td>\n",
       "      <td>100.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>DP=4576;TI=NM_032335,NM_001015877,NM_032458;GI...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:100:4396,180:0.0393:20:-100.0000:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>chrX</td>\n",
       "      <td>133547693</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>TA</td>\n",
       "      <td>100.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>DP=4493;TI=NM_032335,NM_001015877,NM_032458;GI...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:100:4368,125:0.0278:20:-100.0000:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>chrX</td>\n",
       "      <td>133547816</td>\n",
       "      <td>.</td>\n",
       "      <td>AT</td>\n",
       "      <td>A</td>\n",
       "      <td>100.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>DP=979;TI=NM_032335,NM_001015877,NM_032458;GI=...</td>\n",
       "      <td>GT:GQ:AD:VF:NL:SB:GQX</td>\n",
       "      <td>0/1:100:943,36:0.0368:20:-48.6825:100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CHROM        POS ID REF ALT   QUAL FILTER  \\\n",
       "0    chr1   36931706  .   T   G   32.0     SB   \n",
       "1    chr1   36932103  .   T   G   62.0     SB   \n",
       "2    chr1   36932108  .   A   C   43.0     SB   \n",
       "3    chr1   36932121  .   C   G   65.0     SB   \n",
       "4    chr1   36932122  .   T   G  100.0     SB   \n",
       "..    ...        ... ..  ..  ..    ...    ...   \n",
       "454  chrX  133527688  .   G  GT  100.0     R8   \n",
       "455  chrX  133527928  .  AT   A   50.0   PASS   \n",
       "456  chrX  133547693  .  TA   T  100.0   PASS   \n",
       "457  chrX  133547693  .   T  TA  100.0   PASS   \n",
       "458  chrX  133547816  .  AT   A  100.0   PASS   \n",
       "\n",
       "                                                  INFO                 FORMAT  \\\n",
       "0    DP=1055;TI=NM_172313,NM_156039,NM_000760;GI=CS...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "1    DP=2094;TI=NM_172313,NM_156039,NM_000760;GI=CS...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "2    DP=2136;TI=NM_172313,NM_156039,NM_000760;GI=CS...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "3    DP=321;TI=NM_172313,NM_156039,NM_000760;GI=CSF...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "4    DP=333;TI=NM_172313,NM_156039,NM_000760;GI=CSF...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "..                                                 ...                    ...   \n",
       "454  DP=1090;TI=NM_032335,NM_001015877,NM_032458;GI...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "455  DP=1395;TI=NM_032335,NM_001015877,NM_032458;GI...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "456  DP=4576;TI=NM_032335,NM_001015877,NM_032458;GI...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "457  DP=4493;TI=NM_032335,NM_001015877,NM_032458;GI...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "458  DP=979;TI=NM_032335,NM_001015877,NM_032458;GI=...  GT:GQ:AD:VF:NL:SB:GQX   \n",
       "\n",
       "                                     W1717693  \n",
       "0          0/1:32:1031,23:0.0218:20:0.0000:32  \n",
       "1          0/1:62:2031,47:0.0224:20:0.0000:62  \n",
       "2          0/1:43:2083,42:0.0197:20:0.0000:43  \n",
       "3          0/1:65:305,16:0.0498:20:-0.2685:65  \n",
       "4        0/1:100:304,26:0.0781:20:-0.2588:100  \n",
       "..                                        ...  \n",
       "454   0/1:100:1000,90:0.0826:20:-100.0000:100  \n",
       "455      0/1:50:1362,33:0.0237:20:-22.4949:50  \n",
       "456  0/1:100:4396,180:0.0393:20:-100.0000:100  \n",
       "457  0/1:100:4368,125:0.0278:20:-100.0000:100  \n",
       "458     0/1:100:943,36:0.0368:20:-48.6825:100  \n",
       "\n",
       "[459 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataA = pd.read_csv(NAME_FILE_1, comment='#', delimiter='\\t', names=load_sample (NAME_FILE_1))\n",
    "dataA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_sample(data,NAME_FILE):\n",
    "    '''\n",
    "    VCF files can have 1 or > 1 samples\n",
    "    We need to know what sample the user wants to compare\n",
    "    After this, the data of the sample is all staored in the same  column\n",
    "    to access the data, it needs to be splited in different columns\n",
    "    '''\n",
    "    if len(data.columns) > 10:\n",
    "        Name_sample = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(NAME_FILE)))\n",
    "    else:\n",
    "        print('File', os.path.basename(NAME_FILE), 'contains one sample only.')\n",
    "        Name_sample = data.columns.tolist()[9]\n",
    "    \n",
    "    tmp_df_2 = data[Name_sample].str.split(':', expand=True)\n",
    "    # I have seen very unlikely Na values\n",
    "    # To solve this, they are deleted\n",
    "    tmp_df_2 = tmp_df_2.fillna(value=np.nan)\n",
    "    tmp_df_2 = tmp_df_2.dropna(axis=1, how='any')\n",
    "    # To get the name of the new columns created\n",
    "    tmp_df_2.columns = data.FORMAT.iloc[0].split(':')\n",
    "    return pd.concat([data, tmp_df_2], axis=1),Name_sample\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File W1717693_S1.vcf contains one sample only.\n"
     ]
    }
   ],
   "source": [
    "dataA,Name_sample_1 = take_sample(dataA,NAME_FILE_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_1(data):\n",
    "    return data.query('FILTER == \"PASS\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_2(data):\n",
    "    if \"VF\" in data.columns:\n",
    "        data[\"VF\"] = data[\"VF\"].astype(float)\n",
    "    return data.query('VF > 0.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA = filter_2(dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparason(data):\n",
    "    return dataA[\"CHROM\"].apply(str)+\".\"+dataA[\"POS\"].apply(str)+dataA[\"REF\"]+\".\"+dataA[\"ALT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-61ab00b914a6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataA['CHROMPOSREFALT'] = comparason(dataA)\n"
     ]
    }
   ],
   "source": [
    "dataA['CHROMPOSREFALT'] = comparason(dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dataA[['CHROMPOSREFALT', 'GT']],dataA[['CHROMPOSREFALT', 'GT']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROMPOSREFALT</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chr1.36933096T.C</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chr2.25463483G.A</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chr2.25466888G.T</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>chr2.25469502C.T</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>chr2.198266834T.C</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>chrX.76940534A.G</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>chrX.129147079T.C</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>chrX.129147373G.A</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>chrX.129186012C.T</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>chrX.133511988G.A</td>\n",
       "      <td>1/1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CHROMPOSREFALT   GT\n",
       "10    chr1.36933096T.C  0/1\n",
       "16    chr2.25463483G.A  0/1\n",
       "19    chr2.25466888G.T  1/1\n",
       "30    chr2.25469502C.T  0/1\n",
       "33   chr2.198266834T.C  0/1\n",
       "..                 ...  ...\n",
       "391   chrX.76940534A.G  1/1\n",
       "423  chrX.129147079T.C  1/1\n",
       "424  chrX.129147373G.A  1/1\n",
       "439  chrX.129186012C.T  1/1\n",
       "447  chrX.133511988G.A  1/1\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_final_df = pd.concat(frames)\n",
    "semi_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see is lists are storing data correctly\n",
    "print(sampleA)\n",
    "print(sampleB)\n",
    "print(Total_positions_comp)\n",
    "print(Pos_same_genotype)\n",
    "print(Pos_different_genotyope)\n",
    "print(Hom)\n",
    "print(Het)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lists in a df\n",
    "results = pd.DataFrame(list(zip(sampleA, sampleB,Total_positions_comp,Pos_same_genotype,Pos_different_genotyope,Hom,Het)),\n",
    "               columns=['Sample_A','Sample_B','Total_positions_comp','Pos_same_genotype','Pos_different_genotyope','Hom','Het'])\n",
    "results = results[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get proportion of sites with common genotype\n",
    "results[\"identical_position (%)\"] = results[\"Pos_same_genotype\"]/results[\"Total_positions_comp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save \n",
    "total_results = pd.read_csv(\"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/Results/both_patients.csv\")\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generater the plot\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.scatterplot(data=total_results, x=\"identical_position (%)\", y=\"Total_positions_comp\",\n",
    "               hue = \"Samples:\",\n",
    "               palette=['red',\"dodgerblue\"], legend='full',\n",
    "               ).set(xlabel=\"Proportion of positions with common genotypes\",\n",
    "                    ylabel=\"Number of positions compared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################### NOOO DELETE THIS ######################################\n",
    "# A Dashboard to show results in case I will needed\n",
    "\n",
    "\n",
    "### 6. Generate a report in a dashboard\n",
    "# Bootstrap themes by Ann: https://hellodash.pythonanywhere.com/theme_explorer\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.SIMPLEX])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardImg(src='./assets/wrgllogohighres.jpeg')\n",
    "                ],color=\"light\", outline=True),\n",
    "                ],width=3),\n",
    "                dbc.Col([\n",
    "                    dbc.Card([\n",
    "                        dbc.CardImg(src='./assets/salisbury-nhs-foundation-trustLeft.png')\n",
    "                             ],color=\"light\", outline=True)\n",
    "                        ],width=2)\n",
    "            ],justify=\"between\"),\n",
    "        dbc.Row(\n",
    "            [dbc.Card([ \n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                    html.H1(\"Report: Do the samples belong to the same patient?\"),\n",
    "                    html.H3(\"This application takes common variants and compares the GT fields. A relative large number of common variants which GT fields match is indicative that both samples have a close relationship.\"),\n",
    "                ], style={'textAlign': 'center'}) \n",
    "                     ], style={'textLeft':'center', })      \n",
    "                      ], style={'height':'10vh'},color=\"light\", outline=True),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Card([ \n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                    html.H1(\"\"),\n",
    "                    html.H3(\"\"),\n",
    "                ], style={'textAlign': 'center'}) \n",
    "                     ], style={'textLeft':'center', })      \n",
    "                      ], style={'height':'10vh'},color=\"light\", outline=True),\n",
    "        ]),\n",
    "        dbc.Row([  \n",
    "            dbc.Col([\n",
    "            dash_table.DataTable(\n",
    "        id='datatable-interactivity',\n",
    "        columns=[\n",
    "            {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True, \"hideable\": True}\n",
    "            if i == \"iso_alpha3\" or i == \"year\" or i == \"id\"\n",
    "            else {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True}\n",
    "            for i in final_df.columns\n",
    "        ],\n",
    "        data=final_df.to_dict('records'),  # the contents of the table html.H3(os.path.basename(Name_file1)),\n",
    "        filter_action=\"native\",     # allow filtering of data by user ('native') or not ('none')\n",
    "        sort_action=\"native\",       # enables data to be sorted per-column by user or not ('none')\n",
    "        sort_mode=\"single\",         # sort across 'multi' or 'single' columns\n",
    "        row_deletable=True,         # choose if user can delete a row (True) or not (False)\n",
    "        selected_rows=[],           # indices of rows that user selects\n",
    "        page_action=\"native\",       # all data is passed to the table up-front or not ('none')\n",
    "        page_current=0,             # page number that user is on\n",
    "        style_cell={                # ensure adequate header width when text is shorter than cell's text\n",
    "            'minWidth': 200, 'maxWidth': 95, 'width': 95\n",
    "        },\n",
    "        style_data_conditional=[\n",
    "        {\n",
    "            'if': {'row_index': 'odd'},\n",
    "            'backgroundColor': 'rgb(248, 248, 248)'\n",
    "        }\n",
    "    ],\n",
    "        style_header={\n",
    "        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "        'fontWeight': 'bold'\n",
    "    })]),\n",
    "    dbc.Col([\n",
    "        dbc.Card([ \n",
    "            dbc.CardBody([\n",
    "                html.Div([\n",
    "                    html.H4(\"Number of common variants:\",style={'color': 'black', 'fontSize': 15}),\n",
    "                    html.H4(len(final_df)),\n",
    "                    html.H4(\"Number of matches:\", style={'color': 'black', 'fontSize': 15}),\n",
    "                    html.H4(final_df.Matches.value_counts()[1]),\n",
    "                    ], \n",
    "                    style={'textAlign': 'left'})\n",
    "                    ])\n",
    "                    ],\n",
    "                    style={'height':'8vh'},color=\"light\", outline=True),\n",
    "                    ])\n",
    "                    ])\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
