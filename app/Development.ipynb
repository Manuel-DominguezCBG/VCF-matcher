{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook to develop the script, generate and analyse some results.\n",
    "\n",
    "I have started the development of the program in this notebook. Then, I have adapted the code to have a script\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "Created on \n",
    "\n",
    "@author: manuel.dominguezbecerra@nhs.net\n",
    "\n",
    "'''\n",
    "\n",
    "# Import libraries \n",
    "import argparse                          # pip install argparse\n",
    "import pandas as pd                      \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# To allow the user to load the file after running \"python run.ppy\"\n",
    "\n",
    "# Example:    python run.py -- /path/file_name1 -- /path/file_name2\n",
    "\n",
    "   ### 1. Load the files\n",
    "    \n",
    "# During the development of this application, I have needed to run the script many times\n",
    "# To do this in an easy way, I directly introduce here the path/file_name in a variable\n",
    "# As it can be seen below\n",
    "\n",
    "Name_file1 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2013397_S6.vcf\"\n",
    "\n",
    "Name_file2 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2103016_S15.vcf\"\n",
    "\n",
    "# In the script, the previous two lines doesn´t appear and the following lines are incommeneted\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--vcf1', type=str, required=True)\n",
    "#parser.add_argument('--vcf2', type=int, required=True)\n",
    "#args = parser.parse_args()\n",
    "#Name_file1 = args.vcf1 \n",
    "#Name_file2 = args.vcf2\n",
    "\n",
    "# This 6 lines allow the user to select the two neccesary files to run the script\n",
    "\n",
    "#During the development, the few lines make running the script easier.\n",
    "# In the run.py script, the previous lines are uncommented and the following lines are deleted.\n",
    "\n",
    "\n",
    "# From here to the end, the following lines are identical that the one find in the script\n",
    "\n",
    "\n",
    "   ### 2. Take the body of the files and ignore meta-data lines\n",
    "\n",
    "# Originally what I did was to delete the metedata and save the data in a new file\n",
    "# This approach was over complicated and doesn´t work in window machines.\n",
    "# Instead of this, the current approach  take directly the data and save it in pandas dataframe object.\n",
    "# This is also a more efficient method.\n",
    "\n",
    "# For the file number 1\n",
    "with open(Name_file1, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "\n",
    "dataA = pd.read_csv(Name_file1, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "# Same for the second file\n",
    "with open(Name_file2, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "            \n",
    "dataB = pd.read_csv(Name_file2, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "\n",
    "# If the data frame has more than 10 columns\n",
    "# that means there are more than 1 sample in the vcf file\n",
    "# If more than one file is found, next lines ask to the user what sample to take.\n",
    "\n",
    "if len(dataA.columns) > 10:\n",
    "     Name_sample1 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file1)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file1), 'contains one sample only.')\n",
    "    Name_sample1 = dataA.columns.tolist()[9]\n",
    "\n",
    "if len(dataB.columns) > 10:\n",
    "     Name_sample2 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file2)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file2), 'contains one sample only.')\n",
    "    Name_sample2 = dataB.columns.tolist()[9]\n",
    "\n",
    "    \n",
    "\n",
    "# The data of the sample is save in the file in one column separated by \":\". \n",
    "# Example: Example:   0/1:100:3501,254:0.0676:20:-100.0000:100\n",
    "\n",
    "# To take the data I want, I need to split and put the fiels in columns\n",
    "\n",
    "\n",
    "tmp_df2 = dataA[Name_sample1].str.split(':', expand=True)\n",
    "\n",
    "tmp_df2 = tmp_df2.fillna(value=np.nan)\n",
    "tmp_df2 = tmp_df2.dropna(axis=1, how='any')\n",
    "\n",
    "tmp_df2.columns = dataA.FORMAT.iloc[0].split(':')\n",
    "dataA = pd.concat([dataA, tmp_df2], axis=1)\n",
    "\n",
    "# Results so far\n",
    "#  CHROM       POS ID REF ALT  QUAL FILTER   GT  GQ       AD      VF  NL\n",
    "#  chr1  36931745  .   G   A  34.0     SB  0/1  34  1755,34  0.0190  20\n",
    "\n",
    "# Same for dataB\n",
    "tmp_df3 = dataB[Name_sample2].str.split(':', expand=True)\n",
    "tmp_df3 = tmp_df3.fillna(value=np.nan) \n",
    "tmp_df3 = tmp_df3.dropna(axis=1, how='any') \n",
    "\n",
    "tmp_df3.columns = dataB.FORMAT.iloc[0].split(':')\n",
    "dataB = pd.concat([dataB, tmp_df3], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    ### 3. Filter the variants  \n",
    "    \n",
    "# Two filters are applied here. First, I take only the variants that \"PASS\" the \"FILTER\" field. \n",
    "# This is a mandatory field.\n",
    "\n",
    "# Then, I take only the variants which Variant Frecuency (VF) is highter than. 0.4\n",
    "# This is not a mandatory field in vcf filed\n",
    "\n",
    "# VF is in the 9th column with another data. \n",
    "#we need to extract and put VF data in an independent column first\n",
    "\n",
    "\n",
    "# Now, let´s filter the variant\n",
    "# We dont want variants that doesnt pass the Filter status\n",
    "# This field is mandatory, no condition is needed because it is applied to any type of VCF file.\n",
    "dataA = dataA.query('FILTER == \"PASS\"')\n",
    "dataB = dataB.query('FILTER == \"PASS\"')\n",
    "                    \n",
    "# Now, I apply Variant Frecuency (VF) filter (non-mandatory field)\n",
    "\n",
    "# If there is a VF Genotype fields in the file\n",
    "# Take the variants that are > 0.4\n",
    "# If not, no VF filter is applied\n",
    "\n",
    "if \"VF\" in dataA.columns:\n",
    "    dataA[\"VF\"] = dataA[\"VF\"].astype(float)\n",
    "    dataA = dataA.query('VF > 0.4')\n",
    "    \n",
    "if \"VF\" in dataB.columns:\n",
    "    dataB[\"VF\"] = dataB[\"VF\"].astype(float)\n",
    "    dataB = dataB.query('VF > 0.4')\n",
    "    \n",
    "\n",
    "   ### 4. Variants comparison\n",
    "\n",
    "# Two variants are the same if  CHROM, POS, REF, ALT and GT are equal\n",
    "\n",
    "dataA['CHROMPOSREFALT']= dataA[\"CHROM\"].apply(str)+\".\"+dataA[\"POS\"].apply(str)+dataA[\"REF\"]+\".\"+dataA[\"ALT\"]\n",
    "\n",
    "dataB['CHROMPOSREFALT']= dataB[\"CHROM\"].apply(str)+\".\"+dataB[\"POS\"].apply(str)+dataB[\"REF\"]+\".\"+dataB[\"ALT\"]\n",
    "\n",
    "\n",
    "frames = [dataA[['CHROMPOSREFALT', 'GT']],dataB[['CHROMPOSREFALT', 'GT']]]\n",
    "semi_final_df = pd.concat(frames)\n",
    "# semi_final_df saves the CHROM, POS, REF, ALT in the first column and the GT in the second column\n",
    "\n",
    "\n",
    "#Example:\n",
    "'''\n",
    "CHROMPOSREFALT     GT\n",
    "\n",
    "chr1.123456T.C     0/1       From sample 1\n",
    "chr2.123456A.C     1/1       From sample 1\n",
    "chr1.123456T.C     0/1       From sample 2\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Let´s reduce the number of rows\n",
    "final_df=(semi_final_df.assign(key=semi_final_df.groupby('CHROMPOSREFALT').cumcount())\n",
    "      .pivot('CHROMPOSREFALT','key','GT')\n",
    "      .rename(columns=lambda x:f\"Sample{x+1}\")\n",
    "      .rename_axis(columns=None).reset_index())\n",
    "\n",
    "# Final_df contains all common and non-common variants that passed the filters\n",
    "\n",
    "# The pivot command gives NaNs in the column of the second sample when a variant is only found in one of the samples\n",
    "# This NaN values return errors in the following lines. This is an error I have found when the script was developed\n",
    "# To solve the issue without introducing many changes, NaN values are replace for 99/99 values.\n",
    "final_df = final_df.replace(np.NaN,\"99/99\" )\n",
    "\n",
    "   ### 4. See how many GT match\n",
    "\n",
    "# Variables needed for both type of reports\n",
    "\n",
    "r0 = os.path.basename(Name_file1) # Get the  file name of a path/file_name \n",
    "r1 = Name_sample1                 # Get the name of the sample 1\n",
    "r2 = os.path.basename(Name_file2)\n",
    "r3 = Name_sample2\n",
    "\n",
    "if \"Sample2\" not in final_df.columns:\n",
    "    # If Sample2 is not in final_df, that means there is not common position between the samples.\n",
    "    report0 = '''\n",
    " _____________________________  REPORT  ________________________________________ \n",
    "\n",
    "vcf 1: {0}  AND its sample name: {1}  \n",
    "vcf 2:  {2}  AND its sample name: {3}\n",
    "\n",
    "   No common positions found between samples\n",
    "\n",
    " ____________________________ END REPORT  _______________________________________\n",
    "'''\n",
    "    print(report0.format(r0,r1,r2,r3,))\n",
    "\n",
    "else:    \n",
    "    # else match common position and carry on the report.\n",
    "    final_df[\"Matches\"] = np.where(final_df[\"Sample1\"] == final_df[\"Sample2\"], True, False)\n",
    "    final_df.columns = ['CHROMPOSREFALT',os.path.basename(Name_file1),os.path.basename(Name_file2),\"Matches\" ]\n",
    "\n",
    "    # 6.  To get hom and het \n",
    "\n",
    "    final_df['Genotype1'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[0])\n",
    "    final_df['Genotype2'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[1])\n",
    "    \n",
    "    final_df['Hom/het'] = np.select([final_df['Matches'] & final_df['Genotype1'].eq(final_df['Genotype2']),\n",
    "                       final_df['Matches'] & final_df['Genotype1'].ne(final_df['Genotype2'])],\n",
    "                       choicelist=[\"Hom\", \"Het\"],\n",
    "                       default=pd.NA)\n",
    "\n",
    "   ### 6. Generate results in the terminal\n",
    "\n",
    "# Variable to introduce in the report :\n",
    "    \n",
    "    r4 = final_df['Matches'].value_counts().get(True, 0) # Count trues if any, retunr 0\n",
    "    r5 = final_df['Hom/het'].value_counts().get(\"Hom\", 0)\n",
    "    r6 =final_df['Hom/het'].value_counts().get(\"Het\", 0)\n",
    "    r7 = final_df['Matches'].value_counts().get(False, 0)\n",
    "    r8 = len(final_df)\n",
    "    r9 = r4/(r4+r7)\n",
    "    report = '''\n",
    " _____________________________  REPORT  ________________________________________ \n",
    "\n",
    "vcf 1: {0}  AND its sample name: {1}  \n",
    "vcf 2:  {2}  AND its sample name: {3}\n",
    "\n",
    "                                                  Homozigous: {5} \n",
    "Number of positions with the same genotype: {4} \n",
    "                                                  Heterozigous: {6} \n",
    "                                                \n",
    "                                                  \n",
    "Number of positions with different genotype: {7} \n",
    "                                                  \n",
    "\n",
    "\n",
    "Total positions compared: {8}\n",
    "Percentage in common: {4}/{8}= {9}\n",
    "\n",
    " ____________________________ END REPORT  _______________________________________\n",
    "'''\n",
    "    print(report.format(r0,r1,r2,r3,r4,r5,r6,r7,r8,r9))\n",
    "    \n",
    "    # ========== Results ================== #\n",
    "\n",
    "# To store results in lists and then in df\n",
    "\n",
    "# To create the list the first iteration\n",
    "#sampleA = [\"hola\"]\n",
    "#sampleB = [\"hola\"]\n",
    "#Total_positions_comp = [\"hola\"]\n",
    "#Pos_same_genotype = [\"hola\"]\n",
    "#Pos_different_genotyope = [\"hola\"]\n",
    "#Hom = [\"hola\"]\n",
    "#Het = [\"hola\"]\n",
    "\n",
    "#sampleA.append(r1)\n",
    "#sampleB.append(r3)\n",
    "#Total_positions_comp.append(r8)\n",
    "#Pos_same_genotype.append(r4)\n",
    "#Pos_different_genotyope.append(r7)\n",
    "#Hom.append(r5)\n",
    "#Het.append(r6)    \n",
    "\n",
    "\n",
    "\n",
    "# draft\n",
    "\n",
    "#(semi_final_df.pivot_table(index = ['CHROMPOSREDALT'], aggfunc ='size')==2).value_counts()[1] # position same genotipe\n",
    "#position_same_genotype = (semi_final_df.pivot_table(index = ['CHROMPOSREDALT'], aggfunc ='size')==2).value_counts()[1]\n",
    "#total_hom = semi_final_df[semi_final_df.GT == '1/1'].shape[0]\n",
    "#total_het = semi_final_df[semi_final_df.GT != '1/1'].shape[0]\n",
    "#final_df = final_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(semi_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df=final_df.rename(columns = {'final_match':'Hom/het'})\n",
    "final_df[\"Hom/het\"].replace({\"False\": \"Het\",}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB[['CHROMPOSREFALT', 'GT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see is lists are storing data correctly\n",
    "print(sampleA)\n",
    "print(sampleB)\n",
    "print(Total_positions_comp)\n",
    "print(Pos_same_genotype)\n",
    "print(Pos_different_genotyope)\n",
    "print(Hom)\n",
    "print(Het)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lists in a df\n",
    "results = pd.DataFrame(list(zip(sampleA, sampleB,Total_positions_comp,Pos_same_genotype,Pos_different_genotyope,Hom,Het)),\n",
    "               columns=['Sample_A','Sample_B','Total_positions_comp','Pos_same_genotype','Pos_different_genotyope','Hom','Het'])\n",
    "results = results[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get proportion of sites with common genotype\n",
    "results[\"identical_position (%)\"] = results[\"Pos_same_genotype\"]/results[\"Total_positions_comp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save \n",
    "total_results = pd.read_csv(\"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/Results/both_patients.csv\")\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generater the plot\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.scatterplot(data=total_results, x=\"identical_position (%)\", y=\"Total_positions_comp\",\n",
    "               hue = \"Samples:\",\n",
    "               palette=['red',\"dodgerblue\"], legend='full',\n",
    "               ).set(xlabel=\"Proportion of positions with common genotypes\",\n",
    "                    ylabel=\"Number of positions compared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_positions_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_same_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_different_genotyope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.replace(np.NaN,\"99/99\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_file1 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/1/W1815770_S16.vcf\"\n",
    "Name_file2 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/1/W2103070_S8.vcf\"\n",
    "\n",
    "\n",
    "\n",
    "# Files to pandas object\n",
    "with open(Name_file1, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "df = pd.read_csv(Name_file1, comment='#', delimiter='\\t', names=columns)\n",
    "df\n",
    "#import re\n",
    "### 1. Remove the header of input files\n",
    "\n",
    "#print (re.sub(r'^##.*\\n?', '', Name_file1, flags=re.MULTILINE))\n",
    "\n",
    "# File A\n",
    "#cmd = \"sed '/^##/ d'  {0} >  FileA.txt\".format(Name_file1)\n",
    "#os.system(cmd)\n",
    "\n",
    "# File B \n",
    "#cmd = \"sed '/^##/ d'  {0} >  FileB.txt\".format(Name_file2)\n",
    "#os.system(cmd)\n",
    "\n",
    "# Files to pandas object\n",
    "#dataA = pd.read_csv(\"./FileA.txt\", delimiter = \"\\t\" )\n",
    "#dataB = pd.read_csv(\"./FileB.txt\", delimiter = \"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOOOOOOOO BORRARRRR ######################################\n",
    "\n",
    "\n",
    "### 6. Generate a report in a dashboard\n",
    "# Bootstrap themes by Ann: https://hellodash.pythonanywhere.com/theme_explorer\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.SIMPLEX])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardImg(src='./assets/wrgllogohighres.jpeg')\n",
    "                ],color=\"light\", outline=True),\n",
    "                ],width=3),\n",
    "                dbc.Col([\n",
    "                    dbc.Card([\n",
    "                        dbc.CardImg(src='./assets/salisbury-nhs-foundation-trustLeft.png')\n",
    "                             ],color=\"light\", outline=True)\n",
    "                        ],width=2)\n",
    "            ],justify=\"between\"),\n",
    "        dbc.Row(\n",
    "            [dbc.Card([ \n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                    html.H1(\"Report: Do the samples belong to the same patient?\"),\n",
    "                    html.H3(\"This application takes common variants and compares the GT fields. A relative large number of common variants which GT fields match is indicative that both samples have a close relationship.\"),\n",
    "                ], style={'textAlign': 'center'}) \n",
    "                     ], style={'textLeft':'center', })      \n",
    "                      ], style={'height':'10vh'},color=\"light\", outline=True),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Card([ \n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                    html.H1(\"\"),\n",
    "                    html.H3(\"\"),\n",
    "                ], style={'textAlign': 'center'}) \n",
    "                     ], style={'textLeft':'center', })      \n",
    "                      ], style={'height':'10vh'},color=\"light\", outline=True),\n",
    "        ]),\n",
    "        dbc.Row([  \n",
    "            dbc.Col([\n",
    "            dash_table.DataTable(\n",
    "        id='datatable-interactivity',\n",
    "        columns=[\n",
    "            {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True, \"hideable\": True}\n",
    "            if i == \"iso_alpha3\" or i == \"year\" or i == \"id\"\n",
    "            else {\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True}\n",
    "            for i in final_df.columns\n",
    "        ],\n",
    "        data=final_df.to_dict('records'),  # the contents of the table html.H3(os.path.basename(Name_file1)),\n",
    "        filter_action=\"native\",     # allow filtering of data by user ('native') or not ('none')\n",
    "        sort_action=\"native\",       # enables data to be sorted per-column by user or not ('none')\n",
    "        sort_mode=\"single\",         # sort across 'multi' or 'single' columns\n",
    "        row_deletable=True,         # choose if user can delete a row (True) or not (False)\n",
    "        selected_rows=[],           # indices of rows that user selects\n",
    "        page_action=\"native\",       # all data is passed to the table up-front or not ('none')\n",
    "        page_current=0,             # page number that user is on\n",
    "        style_cell={                # ensure adequate header width when text is shorter than cell's text\n",
    "            'minWidth': 200, 'maxWidth': 95, 'width': 95\n",
    "        },\n",
    "        style_data_conditional=[\n",
    "        {\n",
    "            'if': {'row_index': 'odd'},\n",
    "            'backgroundColor': 'rgb(248, 248, 248)'\n",
    "        }\n",
    "    ],\n",
    "        style_header={\n",
    "        'backgroundColor': 'rgb(230, 230, 230)',\n",
    "        'fontWeight': 'bold'\n",
    "    })]),\n",
    "    dbc.Col([\n",
    "        dbc.Card([ \n",
    "            dbc.CardBody([\n",
    "                html.Div([\n",
    "                    html.H4(\"Number of common variants:\",style={'color': 'black', 'fontSize': 15}),\n",
    "                    html.H4(len(final_df)),\n",
    "                    html.H4(\"Number of matches:\", style={'color': 'black', 'fontSize': 15}),\n",
    "                    html.H4(final_df.Matches.value_counts()[1]),\n",
    "                    ], \n",
    "                    style={'textAlign': 'left'})\n",
    "                    ])\n",
    "                    ],\n",
    "                    style={'height':'8vh'},color=\"light\", outline=True),\n",
    "                    ])\n",
    "                    ])\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/1/W1815770_S16.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/1/W2103070_S8.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2013397_S6.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2103016_S15.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/3/W2008872_S8.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/3/W2103014_S10.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/4/W1906436_S11.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/4/W2010731_S10.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/4/W2100789_S9.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/5/W2012950_S3.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/5/W2012950_S10.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/5/W2102707_S6.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/6/W1922549_S1.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/6/W2102681_S3.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/7/W2017353_S16.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/7/W2102609_S15.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/8/W2017475_S3.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/8/W2102400_S16.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/9/W2013237_S11.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/9/W2102210_S7.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/10/W2014615_S12.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/10/W2102164_S5.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/11/W2000136_S7.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/11/W2002769_S14.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/11/W2102033_S6.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/12/W1922376_S2.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/12/W2101810_S7.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/13/W1902904_S9.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/13/W2101694_S12.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/14/W1814542_S10.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/14/W2101517_S1.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/15/W2002517_S15.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/15/W2006956_S14.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/15/W2101417_S2.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/16/W1906283-003_S1.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/16/W2101157_S8.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/17/W2009066_S16.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/17/W2101130_S5.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/18/W1806167_S4.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/18/W2101083_S9.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/19/W2009316_S2.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/19/W2012284_S12.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/19/W2101032_S15.vcf\n",
    "\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/20/W2010438_S4.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/20/W2013228_S11.vcf\n",
    "#/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/20/W2100941_S16.vcf\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import argparse                          # pip install argparse\n",
    "import pandas as pd                      \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# To allow the user to load the file after running \"python run.ppy\"\n",
    "\n",
    "# Example:    python run.py -- /path/file_name1 -- /path/file_name2\n",
    "\n",
    "   ### 1. Load the files\n",
    "    \n",
    "# During the development of this application, I have needed to run the script many times\n",
    "# To do this in an easy way, I directly introduce here the path/file_name in a variable\n",
    "# As it can be seen below\n",
    "\n",
    "Name_file1 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2013397_S6.vcf\"\n",
    "\n",
    "Name_file2 = \"/Users/monkiky/Desktop/VCF-matcher/Samples/Same_patients/2/W2103016_S15.vcf\"\n",
    "\n",
    "# In the script, the previous two lines doesn´t appear and the following lines are incommeneted\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--vcf1', type=str, required=True)\n",
    "#parser.add_argument('--vcf2', type=int, required=True)\n",
    "#args = parser.parse_args()\n",
    "#Name_file1 = args.vcf1 \n",
    "#Name_file2 = args.vcf2\n",
    "\n",
    "# This 6 lines allow the user to select the two neccesary files to run the script\n",
    "\n",
    "#During the development, the few lines make running the script easier.\n",
    "# In the run.py script, the previous lines are uncommented and the following lines are deleted.\n",
    "\n",
    "\n",
    "# From here to the end, the following lines are identical that the one find in the script\n",
    "\n",
    "\n",
    "   ### 2. Take the body of the files and ignore meta-data lines\n",
    "\n",
    "# Originally what I did was to delete the metedata and save the data in a new file\n",
    "# This approach was over complicated and doesn´t work in window machines.\n",
    "# Instead of this, the current approach  take directly the data and save it in pandas dataframe object.\n",
    "# This is also a more efficient method.\n",
    "\n",
    "# For the file number 1\n",
    "with open(Name_file1, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "\n",
    "dataA = pd.read_csv(Name_file1, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "# Same for the second file\n",
    "with open(Name_file2, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('#') and len(line)>2 and line[1] != '#':\n",
    "            columns = line[1:-1].split('\\t')\n",
    "            break\n",
    "            \n",
    "dataB = pd.read_csv(Name_file2, comment='#', delimiter='\\t', names=columns)\n",
    "\n",
    "\n",
    "# If the data frame has more than 10 columns\n",
    "# that means there are more than 1 sample in the vcf file\n",
    "# If more than one file is found, next lines ask to the user what sample to take.\n",
    "\n",
    "if len(dataA.columns) > 10:\n",
    "     Name_sample1 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file1)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file1), 'contains one sample only.')\n",
    "    Name_sample1 = dataA.columns.tolist()[9]\n",
    "\n",
    "if len(dataB.columns) > 10:\n",
    "     Name_sample2 = input('It seems that {} has more than one sample. Please introduce the name of the sample you wish to analyse:  '.format(os.path.basename(Name_file2)))\n",
    "else:\n",
    "    print('File', os.path.basename(Name_file2), 'contains one sample only.')\n",
    "    Name_sample2 = dataB.columns.tolist()[9]\n",
    "\n",
    "    \n",
    "\n",
    "# The data of the sample is save in the file in one column separated by \":\". \n",
    "# Example: Example:   0/1:100:3501,254:0.0676:20:-100.0000:100\n",
    "\n",
    "# To take the data I want, I need to split and put the fiels in columns\n",
    "\n",
    "\n",
    "df2 = dataA[Name_sample1].str.split(':', expand=True)\n",
    "\n",
    "df2 = df2.fillna(value=np.nan)\n",
    "df2 = df2.dropna(axis=1, how='any')\n",
    "\n",
    "df2.columns = dataA.FORMAT.iloc[0].split(':')\n",
    "dataA = pd.concat([dataA, df2], axis=1)\n",
    "\n",
    "# Same for dataB\n",
    "df3 = dataB[Name_sample2].str.split(':', expand=True)\n",
    "df3 = df3.fillna(value=np.nan) \n",
    "df3 = df3.dropna(axis=1, how='any') \n",
    "\n",
    "df3.columns = dataB.FORMAT.iloc[0].split(':')\n",
    "dataB = pd.concat([dataB, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataA[[\"CHROM\",\"POS\",\"ID\",\"REF\",\"ALT\",\"QUAL\",\"FILTER\",   \"GT\",  \"GQ\", \"AD\",\"VF\",\"NL\"]].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'CHROMPOSREFALT':['chr1.00000000001T.C', 'chr1.00000000002T.C', \"chr1.00000000003T.C\",'chr1.00000000004T.C'],\n",
    "        'GT':[\"0/1\", \"0/0\",\"0/0\", \"0/1\"]}\n",
    "\n",
    "simple_semi_final_df_1 = pd.DataFrame(data, columns = ['CHROMPOSREFALT', 'GT'])\n",
    "\n",
    "\n",
    "data = {'CHROMPOSREFALT':['chr1.00000000001T.C', 'chr1.00000000002T.C',\"chr1.00000000003T.C\", 'chrX.00000000003T.C'],\n",
    "        'GT':[\"0/1\", \"0/0\",\"0/1\",\"0/1\"]}\n",
    "\n",
    "simple_semi_final_df_2 = pd.DataFrame(data, columns = ['CHROMPOSREFALT', 'GT'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CHROMPOSREFALT   GT\n",
      "0  chr1.00000000001T.C  0/1\n",
      "1  chr1.00000000002T.C  0/0\n",
      "2  chr1.00000000003T.C  0/1\n",
      "3  chrX.00000000003T.C  0/1\n"
     ]
    }
   ],
   "source": [
    "print(simple_semi_final_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROMPOSREFALT</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1.00000000001T.C</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1.00000000002T.C</td>\n",
       "      <td>0/0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1.00000000003T.C</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chrX.00000000003T.C</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CHROMPOSREFALT   GT\n",
       "0  chr1.00000000001T.C  0/1\n",
       "1  chr1.00000000002T.C  0/0\n",
       "2  chr1.00000000003T.C  0/1\n",
       "3  chrX.00000000003T.C  0/1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_semi_final_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [simple_semi_final_df_1[['CHROMPOSREFALT', 'GT']],simple_semi_final_df_2[['CHROMPOSREFALT', 'GT']]]\n",
    "semi_final_df = pd.concat(frames)\n",
    "\n",
    "final_df=(semi_final_df.assign(key=semi_final_df.groupby('CHROMPOSREFALT').cumcount())\n",
    "      .pivot('CHROMPOSREFALT','key','GT')\n",
    "      .rename(columns=lambda x:f\"Sample{x+1}\")\n",
    "      .rename_axis(columns=None).reset_index())\n",
    "final_df = final_df.replace(np.NaN,\"99/99\" ) # To avoid future error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"Matches\"] = np.where(final_df[\"Sample1\"] == final_df[\"Sample2\"], True, False)\n",
    "\n",
    "    # 6.  To get hom and het \n",
    "\n",
    "final_df['Genotype1'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[0])\n",
    "final_df['Genotype2'] = final_df.iloc[:,2].apply(lambda x: x.split('/' or '|')[1])\n",
    "    \n",
    "final_df['Hom/het'] = np.select([final_df['Matches'] & final_df['Genotype1'].eq(final_df['Genotype2']),\n",
    "                       final_df['Matches'] & final_df['Genotype1'].ne(final_df['Genotype2'])],\n",
    "                       choicelist=[\"Hom\", \"Het\"],\n",
    "                       default=pd.NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROMPOSREFALT</th>\n",
       "      <th>Sample1</th>\n",
       "      <th>Sample2</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Genotype1</th>\n",
       "      <th>Genotype2</th>\n",
       "      <th>Hom/het</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1.00000000001T.C</td>\n",
       "      <td>0/1</td>\n",
       "      <td>0/1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1.00000000002T.C</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1.00000000003T.C</td>\n",
       "      <td>0/0</td>\n",
       "      <td>0/1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1.00000000004T.C</td>\n",
       "      <td>0/1</td>\n",
       "      <td>99/99</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chrX.00000000003T.C</td>\n",
       "      <td>0/1</td>\n",
       "      <td>99/99</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CHROMPOSREFALT Sample1 Sample2  Matches Genotype1 Genotype2 Hom/het\n",
       "0  chr1.00000000001T.C     0/1     0/1     True         0         1     Het\n",
       "1  chr1.00000000002T.C     0/0     0/0     True         0         0     Hom\n",
       "2  chr1.00000000003T.C     0/0     0/1    False         0         1    <NA>\n",
       "3  chr1.00000000004T.C     0/1   99/99    False        99        99    <NA>\n",
       "4  chrX.00000000003T.C     0/1   99/99    False        99        99    <NA>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = final_df['Matches'].value_counts().get(True, 0) # Count trues if any, retunr 0\n",
    "r5 = final_df['Hom/het'].value_counts().get(\"Hom\", 0)\n",
    "r6 =final_df['Hom/het'].value_counts().get(\"Het\", 0)\n",
    "r7 = final_df['Matches'].value_counts().get(False, 0)\n",
    "r8 = len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r9 = r4/(r4+r7)\n",
    "r9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                                                  Homozigous: {5} \n",
    "Number of positions with the same genotype: {4} \n",
    "                                                  Heterozigous: {6} \n",
    "                                                \n",
    "                                                  \n",
    "Number of positions with different genotype: {7} \n",
    "                                                  \n",
    "\n",
    "\n",
    "Total positions compared: {8}\n",
    "Percentage in common: {4}/{8}= {9}\n",
    "\n",
    " ____________________________ END REPORT  _______________________________________\n",
    "'''\n",
    "    print(report.format(r0,r1,r2,r3,r4,r5,r6,r7,r8,r9))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
